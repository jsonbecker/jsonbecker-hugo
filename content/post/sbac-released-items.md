---
title: Smarter Balance Released Items Scare Me
author: Jason P. Becker
email: jason.paul.becker@gmail.com
date: 2013-07-23
tags: education, assessment, ccss, sbac
---

[CCSSI Mathematics](http://ccssimath.blogspot.com/2013/06/our-sbac-practice-tests-run-through.html) posted a scathing look at the items released by the [Smarter Balanced Assessment Consortium](http://www.smarterbalanced.org/) (SBAC). While the rest of the internet seems to be obsessed over [Georgia leaving the Partnership for Assessment of College and Careers](http://blogs.edweek.org/edweek/curriculum/2013/07/georgia_drops_out_of_parcc_tes.html)[^absurdity], the real concern should be over the quality of these test items.

[^absurdity]: There was a lot of concern trolling over Georgia leaving PARCC by [Andy Smarick on Twitter and Flypaper](http://www.edexcellence.net/commentary/education-gadfly-daily/flypaper/2013/thats-how-the-consortia-crumble.html). I don't really see this as devastating, nor do I think some kind of supplication to the Tea Party could have changed this. Short of federal mandating of common tests and standards, Georgia was never going to stay aligned with a consortium that includes Massachusetts. Georgia has an incredibly inexpensive testing program, because they have built really poor assessments that are almost entirely multiple choice. They also have some of the [lowest proficiency standards in the country](http://educationnext.org/despite-common-core-states-still-lack-common-standards/). There was no way this state would move up to a testing regime that costs more than twice as much (but is around the country median) that is substantially more complex and will have a much higher standard for proficiency. Georgia is one of those states that clearly demonstrates some of the "soft bigotry of low expectations" by hiding behind inflated proficiency due to low standards.

Although CCSSI also deligently point out questions that are not well aligned to the standards, this is the least of my worries. Adjusting the difficulty of items and better alignment is something that testing companies know how to do and deal with all the time. Computerized testing is the new ground and a big part of why states are, rightfully, excited about the consortium. 

The problem with the SBAC items is they represent the worst of computerized assessment. Rather than demonstrating more authentic and complex tasks, they present convoluted scenarios and even more convoluted input methods. Rather than present multimedia in a way that is authentic to the tasks, we see heavy language describing how to input what amounts to multiple choice or fill-in the blank answers. What I see here is not worth the investment in time and equipment that states are being asked to make, and it is hardly a "next generation" set of items that will allow us to attain more accurate measures of achievement. 

SBAC looks poised to set up students to fail because of the mechanations of test taking. This is not only tragic at face value, but assures an increase in test-prep as the items are less authentic.
